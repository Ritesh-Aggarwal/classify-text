{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f912eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd, xgboost, numpy as np, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b902ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Text</th>\n",
       "      <th>Start-Indices</th>\n",
       "      <th>End-Indices</th>\n",
       "      <th>Text-Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://stackoverflow.com/questions/37958781</td>\n",
       "      <td>So does that mean it is better than the defaul...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://stackoverflow.com/questions/37958781</td>\n",
       "      <td>It is fundamentally a heuristic based approach...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://stackoverflow.com/questions/37958781</td>\n",
       "      <td>Calling it a heuristic approach is not meant t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://stackoverflow.com/questions/37958781</td>\n",
       "      <td>The text in question was Moby Dick, and the od...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://stackoverflow.com/questions/37958783</td>\n",
       "      <td>A table containing only debit and credit colum...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            URL  \\\n",
       "0  https://stackoverflow.com/questions/37958781   \n",
       "1  https://stackoverflow.com/questions/37958781   \n",
       "2  https://stackoverflow.com/questions/37958781   \n",
       "3  https://stackoverflow.com/questions/37958781   \n",
       "4  https://stackoverflow.com/questions/37958783   \n",
       "\n",
       "                                                Text Start-Indices  \\\n",
       "0  So does that mean it is better than the defaul...            []   \n",
       "1  It is fundamentally a heuristic based approach...            []   \n",
       "2  Calling it a heuristic approach is not meant t...            []   \n",
       "3  The text in question was Moby Dick, and the od...            []   \n",
       "4  A table containing only debit and credit colum...            []   \n",
       "\n",
       "  End-Indices  Text-Type  \n",
       "0          []          0  \n",
       "1          []          0  \n",
       "2          []          0  \n",
       "3          []          0  \n",
       "4          []          0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data.csv\")\n",
    "data.columns = [\"URL\", \"Text\", \"Start-Indices\", \"End-Indices\", \"Text-Type\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65526949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "686d6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = data[\"Text\"]\n",
    "trainDF['label'] = data[\"Text-Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74f0807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f8e35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3993d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a204692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8983682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9354784081287045\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(max_iter=1000), xtrain_count, train_y, xvalid_count)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05d30db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r\"(?u)\\b\\w\\w+\\b\", ngram_range=(2,3), max_features=5000)\n",
    "# tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a8d4cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 157   14 1410]\n",
      " [  16   46  231]\n",
      " [  12   10 1647]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.10      0.18      1581\n",
      "           1       0.66      0.16      0.25       293\n",
      "           2       0.50      0.99      0.66      1669\n",
      "\n",
      "    accuracy                           0.52      3543\n",
      "   macro avg       0.67      0.41      0.37      3543\n",
      "weighted avg       0.67      0.52      0.41      3543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train1, y_test = train_test_split(xtrain_tfidf_ngram, train_y, test_size=0.20)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(X_train, y_train1)\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
