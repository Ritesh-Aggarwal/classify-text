{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Text</th>\n",
       "      <th>Start-Indices</th>\n",
       "      <th>End-Indices</th>\n",
       "      <th>Text-Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://stackoverflow.com/questions/37958781</td>\n",
       "      <td>So does that mean it is better than the defaul...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://stackoverflow.com/questions/37958781</td>\n",
       "      <td>It is fundamentally a heuristic based approach...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://stackoverflow.com/questions/37958781</td>\n",
       "      <td>Calling it a heuristic approach is not meant t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://stackoverflow.com/questions/37958781</td>\n",
       "      <td>The text in question was Moby Dick, and the od...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://stackoverflow.com/questions/37958783</td>\n",
       "      <td>A table containing only debit and credit colum...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            URL  \\\n",
       "0  https://stackoverflow.com/questions/37958781   \n",
       "1  https://stackoverflow.com/questions/37958781   \n",
       "2  https://stackoverflow.com/questions/37958781   \n",
       "3  https://stackoverflow.com/questions/37958781   \n",
       "4  https://stackoverflow.com/questions/37958783   \n",
       "\n",
       "                                                Text Start-Indices  \\\n",
       "0  So does that mean it is better than the defaul...            []   \n",
       "1  It is fundamentally a heuristic based approach...            []   \n",
       "2  Calling it a heuristic approach is not meant t...            []   \n",
       "3  The text in question was Moby Dick, and the od...            []   \n",
       "4  A table containing only debit and credit colum...            []   \n",
       "\n",
       "  End-Indices  Text-Type  \n",
       "0          []          0  \n",
       "1          []          0  \n",
       "2          []          0  \n",
       "3          []          0  \n",
       "4          []          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Referred Article : https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"../data.csv\")\n",
    "data.columns = [\"URL\", \"Text\", \"Start-Indices\", \"End-Indices\", \"Text-Type\"]\n",
    "#data[\"Text-Type\"] = 5\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = data[\"Text\"]\n",
    "trainDF['label'] = data[\"Text-Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentence_corpus=[]\n",
    "for sentence in trainDF[\"text\"]:\n",
    "    sentence_corpus.append(nltk.word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.Word2Vec(sentence_corpus, min_count=1,vector_size=300,workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:734\u001b[0m, in \u001b[0;36mKeyedVectors.vocab\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvocab\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 734\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    735\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe vocab attribute was removed from KeyedVector in Gensim 4.0.0.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse KeyedVector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms .key_to_index dict, .index_to_key list, and methods \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "print(list(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tw = TweetTokenizer()\n",
    "sentence_corpus_tweety=[]\n",
    "for sentence in trainDF[\"text\"]:\n",
    "    sentence_corpus_tweety.append(tw.tokenize(sentence))\n",
    "print(sentence_corpus_tweety[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tweety = gensim.models.Word2Vec(sentence_corpus_tweety, min_count=1,size=300,workers=4)\n",
    "print(list(model_tweety.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similar_by_word(\"void\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tweety.similar_by_word(\"found\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(set(list(model.wv.vocab)).symmetric_difference(set(list(model_tweety.wv.vocab)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(list(model.wv.vocab))-set(list(model_tweety.wv.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(list(model_tweety.wv.vocab))-set(list(model.wv.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(sentence_corpus, total_examples=len(sentence_corpus), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(sentence_corpus)\n",
    "sequences = tokenizer_obj.texts_to_sequences(sentence_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(s.split()) for s in data[\"Text\"]])\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "word_index =tokenizer_obj.word_index\n",
    "review_pad = pad_sequences(sequences,maxlen=max_length)\n",
    "print(review_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.txt'\n",
    "model.wv.save_word2vec_format(filename,binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "embeddings_index = {}\n",
    "f=open(os.path.join('','model.txt'),encoding='utf-8')\n",
    "for line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    coefs=numpy.asarray(values[1:])\n",
    "    embeddings_index[word]=coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(word_index)+1\n",
    "EMBEDDING_DIM=300\n",
    "embedding_matrix=numpy.zeros((num_words,EMBEDDING_DIM))\n",
    "for word,i in word_index.items():\n",
    "    if i>num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i]=embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM,GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "model = Sequential()\n",
    "embedding_layer=Embedding(num_words,EMBEDDING_DIM,embeddings_initializer=Constant(embedding_matrix),input_length=max_length,trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(GRU(units=32,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(3,activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT=0.2\n",
    "indices=numpy.arange(review_pad.shape[0])\n",
    "numpy.random.shuffle(indices)\n",
    "review_pad=review_pad[indices]\n",
    "y=data[\"Text-Type\"][indices]\n",
    "num_validation_samples=int(VALIDATION_SPLIT*review_pad.shape[0])\n",
    "X_train=review_pad[:-num_validation_samples]\n",
    "y_train=y[:-num_validation_samples]\n",
    "X_test=review_pad[-num_validation_samples:]\n",
    "y_test=y[-num_validation_samples:]\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_binary_train = to_categorical(y_train)\n",
    "y_binary_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_binary_train,batch_size=128,epochs=25,validation_data=(X_test,y_binary_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
